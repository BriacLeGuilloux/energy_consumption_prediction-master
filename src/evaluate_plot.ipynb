{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy consumption prediction using LSTM/GRU in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local module\n",
    "from fct import GRUNet, LSTMNet, move_sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models\n",
    "#### __Note: Running the following codes needs at least 16GB of memory.__\n",
    "Moving on to measuring the accuracy of both models, we'll now use our `evaluate()` function and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of parameters\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accès aux variables\n",
    "label_col_index = config[\"label_col_index\"]\n",
    "inputs_cols_indices = config[\"inputs_cols_indices\"]\n",
    "window_size = config[\"window_size\"]\n",
    "num_files_for_dataset = config[\"num_files_for_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_raw_path = Path.cwd().parent / \"data\" / \"raw\"\n",
    "data_processed_path = Path.cwd().parent / \"data\" / \"processed\"\n",
    "model_path = Path.cwd().parent / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380291d5f40d493c8e57ddcefcdfa15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AEP_hourly.csv ...\n",
      "(121183, 90, 5) (121183, 1)\n",
      "Processing COMED_hourly.csv ...\n",
      "(66407, 90, 5) (66407, 1)\n",
      "Processing DAYTON_hourly.csv ...\n",
      "(121185, 90, 5) (121185, 1)\n",
      "Processing DEOK_hourly.csv ...\n",
      "(57649, 90, 5) (57649, 1)\n",
      "Processing DOM_hourly.csv ...\n",
      "(116099, 90, 5) (116099, 1)\n"
     ]
    }
   ],
   "source": [
    "# The scaler objects will be stored in this dictionary so that our output test data from the model can be re-scaled during evaluation\n",
    "label_scalers = {}\n",
    "\n",
    "train_x = []\n",
    "test_x = {}\n",
    "test_y = {}\n",
    "\n",
    "# Skipping the files we're not using\n",
    "processing_files = [\n",
    "    file for file in os.listdir(data_raw_path) if os.path.splitext(file)[1] == \".csv\"\n",
    "]\n",
    "\n",
    "for file in tqdm_notebook(processing_files[:num_files_for_dataset]):\n",
    "    print(f\"Processing {file} ...\")\n",
    "    # Store csv file in a Pandas DataFrame\n",
    "    df = pd.read_csv(os.path.join(data_raw_path, file), parse_dates=[\"Datetime\"])\n",
    "\n",
    "    # Processing the time data into suitable input formats\n",
    "    df = df.assign(\n",
    "        hour=df[\"Datetime\"].dt.hour,\n",
    "        dayofweek=df[\"Datetime\"].dt.dayofweek,\n",
    "        month=df[\"Datetime\"].dt.month,\n",
    "        dayofyear=df[\"Datetime\"].dt.dayofyear,\n",
    "    )\n",
    "    df = df.sort_values(\"Datetime\").drop(\"Datetime\", axis=1)\n",
    "\n",
    "    # Scaling the input data\n",
    "    sc = MinMaxScaler()\n",
    "    label_sc = MinMaxScaler()\n",
    "    data = sc.fit_transform(df.values)\n",
    "    \n",
    "\n",
    "    # Obtaining the scaler for the labels(usage data) so that output can be\n",
    "    # re-scaled to actual value during evaluation\n",
    "    label_sc.fit(df.iloc[:, label_col_index].values.reshape(-1, 1))\n",
    "    label_scalers[file] = label_sc\n",
    "\n",
    "    # Move the window\n",
    "    inputs, labels = move_sliding_window(\n",
    "        data,\n",
    "        window_size,\n",
    "        inputs_cols_indices=inputs_cols_indices,\n",
    "        label_col_index=label_col_index,\n",
    "    )\n",
    "    \n",
    "    # Redure the precision of data\n",
    "    data = data.astype(np.float32)\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    labels = labels.astype(np.float32)\n",
    "\n",
    "    # CONCAT created instances from all .csv files.\n",
    "    # Split data into train/test portions and combining all data from different files into a single array\n",
    "    test_portion = int(0.1 * len(inputs))\n",
    "    if len(train_x) == 0:  # first iteration\n",
    "        train_x = inputs[:-test_portion]\n",
    "        train_y = labels[:-test_portion]\n",
    "    else:\n",
    "        train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
    "        train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
    "    test_x[file] = inputs[-test_portion:]\n",
    "    test_y[file] = labels[-test_portion:]\n",
    "    \n",
    "    # Remove temporary variables\n",
    "    del df, data, inputs, labels\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accès aux variables\n",
    "n_hidden = config[\"n_hidden\"]\n",
    "hidden_dim = n_hidden\n",
    "input_dim = config[\"input_dim\"]\n",
    "output_dim = config[\"output_dim\"]\n",
    "n_layers = config[\"n_layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move device to cpu for evaluation to avoid GPU memory run\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "gru_model.load_state_dict(torch.load(os.path.join(model_path, \"gru_model.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (gru): GRU(5, 32, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the appropriate device\n",
    "gru_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "lstm_model.load_state_dict(torch.load(os.path.join(model_path, \"lstm_model.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMNet(\n",
       "  (lstm): LSTM(5, 32, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the appropriate device\n",
    "lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "For the purpose of comparing the performance of both models as well, we'll being tracking the time it takes for the model to train and eventually comparing the final accuracy of both models on the test set. For our accuracy measure, we'll use ***Symmetric Mean Absolute Percentage Error (sMAPE)*** to evaluate the models. *sMAPE* is the sum of the **absolute difference** between the predicted and actual values divided by the average of the predicted and actual value, therefore giving a percentage measuring the amount of error. \n",
    "\n",
    "This is the formula for *sMAPE*:\n",
    "\n",
    "$sMAPE = \\frac{100%}{n} \\sum_{t=1}^n \\frac{|F_t - A_t|}{(|F_t + A_t|)/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(outputs, targets):\n",
    "    sMAPE = (\n",
    "        100\n",
    "        / len(targets)\n",
    "        * np.sum(np.abs(outputs - targets) / (np.abs(outputs + targets)) / 2)\n",
    "    )\n",
    "    return sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.process_time()\n",
    "    # get data of test data for each state\n",
    "    for file in test_x.keys():\n",
    "        inputs = torch.from_numpy(np.array(test_x[file]))\n",
    "        labels = torch.from_numpy(np.array(test_y[file]))\n",
    "\n",
    "        h = model.init_hidden(inputs.shape[0])\n",
    "\n",
    "        # predict outputs\n",
    "        with torch.no_grad():\n",
    "            out, h = model(inputs.to(device).float(), h)\n",
    "\n",
    "        outputs.append(\n",
    "            label_scalers[file]\n",
    "            .inverse_transform(out.cpu().detach().numpy())\n",
    "            .reshape(-1)\n",
    "        )\n",
    "\n",
    "        targets.append(\n",
    "            label_scalers[file].inverse_transform(labels.numpy()).reshape(-1)\n",
    "        )\n",
    "\n",
    "    # Merge all files\n",
    "    concatenated_outputs = np.concatenate(outputs)\n",
    "    concatenated_targets = np.concatenate(targets)\n",
    "\n",
    "    print(f\"Evaluation Time: {time.process_time()-start_time}\")\n",
    "    print(f\"sMAPE: {round(sMAPE(concatenated_outputs, concatenated_targets), 3)}%\")\n",
    "\n",
    "    # list of of targets/outputs for each state\n",
    "    return outputs, targets, sMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 19.500326863\n",
      "sMAPE: 0.3529999852180481%\n"
     ]
    }
   ],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 11.867153252999998\n",
      "sMAPE: 0.5410000085830688%\n"
     ]
    }
   ],
   "source": [
    "lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([16370., 16517., 16935., ..., 17001., 15964., 14809.],\n",
       "       shape=(12118,), dtype=float32),\n",
       " array([11271.   , 11372.999, 11403.   , ..., 15086.   , 14447.999,\n",
       "        13334.999], shape=(6640,), dtype=float32),\n",
       " array([2063., 2061., 2119., ..., 2405., 2250., 2042.],\n",
       "       shape=(12118,), dtype=float32),\n",
       " array([3504.    , 3482.0002, 3380.    , ..., 3851.    , 3575.    ,\n",
       "        3281.    ], shape=(5764,), dtype=float32),\n",
       " array([ 9618.   ,  9803.   ,  9870.   , ..., 13312.   , 12390.001,\n",
       "        11385.   ], shape=(11609,), dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the GRU model may have made smaller errors and edged the LSTM model slightly in terms of performance accuracy, the difference is insignificant and thus inconclusive. There have been many other tests conducted by others comparing both these models but there has largely been no clear winner as to which is the better architecture overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    gru_outputs\n",
    ")  # list of predicted output file for each state (each element has a 1d array for that state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([16494.787, 16559.102, 16948.727, ..., 16809.125, 16386.562,\n",
       "        14816.431], shape=(12118,), dtype=float32),\n",
       " array([11311.874, 11736.216, 11477.399, ..., 14871.391, 14466.329,\n",
       "        13513.114], shape=(6640,), dtype=float32),\n",
       " array([2086.8677, 2086.4172, 2121.4314, ..., 2394.8381, 2298.2175,\n",
       "        2074.6746], shape=(12118,), dtype=float32),\n",
       " array([3554.6465, 3468.8118, 3434.8777, ..., 3728.031 , 3737.2366,\n",
       "        3251.2544], shape=(5764,), dtype=float32),\n",
       " array([ 9903.207, 10062.905, 10007.195, ..., 13397.379, 12485.42 ,\n",
       "        11218.503], shape=(11609,), dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's do some visualizations on random sets of our predicted output vs the actual consumption data for some states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(test_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AEP_hourly.csv',\n",
       " 'COMED_hourly.csv',\n",
       " 'DAYTON_hourly.csv',\n",
       " 'DEOK_hourly.csv',\n",
       " 'DOM_hourly.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 100\n",
    "i = 0\n",
    "df = pd.DataFrame({\n",
    "    \"Time Step\": range(nb),  # ou range(-100, 0) si tu veux des indices négatifs\n",
    "    \"GRU Prediction\": gru_outputs[i][-nb:],\n",
    "    \"LSTM Prediction\": lstm_outputs[i][-nb:],\n",
    "    \"Actual\": targets[i][-nb:]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Step</th>\n",
       "      <th>GRU Prediction</th>\n",
       "      <th>LSTM Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15613.262695</td>\n",
       "      <td>15596.736328</td>\n",
       "      <td>15616.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15185.230469</td>\n",
       "      <td>15045.432617</td>\n",
       "      <td>15476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15036.260742</td>\n",
       "      <td>14420.304688</td>\n",
       "      <td>14665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13748.802734</td>\n",
       "      <td>13593.167969</td>\n",
       "      <td>13680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12943.632812</td>\n",
       "      <td>12940.184570</td>\n",
       "      <td>12927.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>17792.246094</td>\n",
       "      <td>18040.521484</td>\n",
       "      <td>17673.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>17262.681641</td>\n",
       "      <td>17280.298828</td>\n",
       "      <td>17303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>16809.125000</td>\n",
       "      <td>16539.115234</td>\n",
       "      <td>17001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>16386.562500</td>\n",
       "      <td>15874.004883</td>\n",
       "      <td>15964.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>14816.430664</td>\n",
       "      <td>14917.135742</td>\n",
       "      <td>14809.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time Step  GRU Prediction  LSTM Prediction        Actual\n",
       "0           0    15613.262695     15596.736328  15616.000000\n",
       "1           1    15185.230469     15045.432617  15476.000000\n",
       "2           2    15036.260742     14420.304688  14665.000000\n",
       "3           3    13748.802734     13593.167969  13680.000000\n",
       "4           4    12943.632812     12940.184570  12927.000000\n",
       "..        ...             ...              ...           ...\n",
       "95         95    17792.246094     18040.521484  17673.001953\n",
       "96         96    17262.681641     17280.298828  17303.000000\n",
       "97         97    16809.125000     16539.115234  17001.000000\n",
       "98         98    16386.562500     15874.004883  15964.000000\n",
       "99         99    14816.430664     14917.135742  14809.000000\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"df.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Step</th>\n",
       "      <th>GRU Prediction</th>\n",
       "      <th>LSTM Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15613.262695</td>\n",
       "      <td>15596.736328</td>\n",
       "      <td>15616.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15185.230469</td>\n",
       "      <td>15045.432617</td>\n",
       "      <td>15476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15036.260742</td>\n",
       "      <td>14420.304688</td>\n",
       "      <td>14665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13748.802734</td>\n",
       "      <td>13593.167969</td>\n",
       "      <td>13680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12943.632812</td>\n",
       "      <td>12940.184570</td>\n",
       "      <td>12927.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>17792.246094</td>\n",
       "      <td>18040.521484</td>\n",
       "      <td>17673.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>17262.681641</td>\n",
       "      <td>17280.298828</td>\n",
       "      <td>17303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>16809.125000</td>\n",
       "      <td>16539.115234</td>\n",
       "      <td>17001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>16386.562500</td>\n",
       "      <td>15874.004883</td>\n",
       "      <td>15964.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>14816.430664</td>\n",
       "      <td>14917.135742</td>\n",
       "      <td>14809.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time Step  GRU Prediction  LSTM Prediction        Actual\n",
       "0           0    15613.262695     15596.736328  15616.000000\n",
       "1           1    15185.230469     15045.432617  15476.000000\n",
       "2           2    15036.260742     14420.304688  14665.000000\n",
       "3           3    13748.802734     13593.167969  13680.000000\n",
       "4           4    12943.632812     12940.184570  12927.000000\n",
       "..        ...             ...              ...           ...\n",
       "95         95    17792.246094     18040.521484  17673.001953\n",
       "96         96    17262.681641     17280.298828  17303.000000\n",
       "97         97    16809.125000     16539.115234  17001.000000\n",
       "98         98    16386.562500     15874.004883  15964.000000\n",
       "99         99    14816.430664     14917.135742  14809.000000\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/backend_bases.py:2295\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2289\u001b[39m     renderer = _get_renderer(\n\u001b[32m   2290\u001b[39m         \u001b[38;5;28mself\u001b[39m.figure,\n\u001b[32m   2291\u001b[39m         functools.partial(\n\u001b[32m   2292\u001b[39m             print_method, orientation=orientation)\n\u001b[32m   2293\u001b[39m     )\n\u001b[32m   2294\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m-> \u001b[39m\u001b[32m2295\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[32m   2298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches == \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/artist.py:74\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     76\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/artist.py:51\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/figure.py:2845\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   2842\u001b[39m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m2845\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.subfigs:\n\u001b[32m   2849\u001b[39m     sfig.draw(renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/image.py:132\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    135\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/artist.py:51\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/axes/_base.py:3055\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3052\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m spine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.spines.values():\n\u001b[32m   3053\u001b[39m         artists.remove(spine)\n\u001b[32m-> \u001b[39m\u001b[32m3055\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_title_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axison:\n\u001b[32m   3058\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_axis_list():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/matplotlib/axes/_base.py:2987\u001b[39m, in \u001b[36m_AxesBase._update_title_position\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   2985\u001b[39m             ax.apply_aspect()\n\u001b[32m   2986\u001b[39m         axs = axs + [ax]\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m top = -\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInf\u001b[49m\n\u001b[32m   2988\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axs:\n\u001b[32m   2989\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (ax.xaxis.get_ticks_position() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mtop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   2990\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m ax.xaxis.get_label_position() == \u001b[33m'\u001b[39m\u001b[33mtop\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.var/app/com.visualstudio.code/cache/pypoetry/virtualenvs/energy-consumption-prediction-master-YcCQwa7r-py3.12/lib/python3.12/site-packages/numpy/__init__.py:781\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    778\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    782\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    784\u001b[39m         name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    785\u001b[39m     )\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33mchararray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    788\u001b[39m     warnings.warn(\n\u001b[32m    789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    791\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor bytes dtype instead.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: `np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(\n",
    "    lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2\n",
    ")\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[0]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[1]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[2]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n",
    "plt.title(f\"Energy Consumption for {states_list[3]} state\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the models are largely successful in predicting the trends of energy consumption. While they may still get some changes wrong, such as delays in predicting a drop in consumption, the predictions follow very closely to the actual line on the test set. This is due to the nature of energy consumption data and the fact that there are patterns and cyclical changes that the model can account for. Tougher time-series prediction problems such as stock price prediction or sales volume prediction may have data that is largely random or doesn’t have predictable patterns, and in such cases, the accuracy will definitely be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use more data.\n",
    "* Use more complex (more layers) networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy-consumption-prediction-master-YcCQwa7r-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
